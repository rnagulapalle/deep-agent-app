from pathlib import Path

from dotenv import load_dotenv
from langchain_anthropic import ChatAnthropic
from langchain_core.tools import tool
from deepagents import create_deep_agent

load_dotenv()

# ---- LLMs ----

# Main planner / executor (more deterministic)
claude = ChatAnthropic(
    model="claude-sonnet-4-5-20250929",  # EXACT ID from your Anthropic console
    temperature=0.1,
    max_tokens=1024,
)

print(f"[BOOT] Using Anthropic model: {claude.model!r}")


# ---- Tools ----


@tool
def web_search(query: str) -> str:
    """Search the web for info on a query (mocked)."""
    return f"Mock results for '{query}': key facts from recent sources."


# ---- Deep Agent ----

# main_agent = create_deep_agent(
#     model=claude,
#     tools=[web_search],
#     system_prompt=(
#         "You are a deep research agent. Break work into TODOs, use tools as needed, "
#         "and produce a clear, well-structured markdown report."
#     ),
# )
main_agent = create_deep_agent(
    model=claude,
    tools=[web_search],
    system_prompt=(
        "You are a fast research agent. Do NOT overthink. "
        "Use at most 3 TODO steps and respond with a short markdown report."
    ),
)



def sanity_test():
    print("[TEST] Running direct Claude sanity test...")
    resp = claude.invoke(
        "Say 'hello Raj, Claude connection works.' in one short sentence."
    )
    # Only print the text, not the whole metadata blob
    print("[TEST] Claude sanity response:", resp.content)


def run_research(topic: str):
    task = (
        f"Research: {topic}. "
        f"Give a short, clear markdown report. Do not create TODO lists."
    )

    print("[AGENT] Running fast mode...")

    result = main_agent.invoke(
        {
            "messages": [
                {"role": "user", "content": task}
            ]
        },
        config={
            "recursion_limit": 12,  # keep planning shallow
            # "max_steps": 4,       # you can re-enable if needed
        },
    )

    # Extract text
    output_text = None
    if isinstance(result, dict):
        # Case 1: DeepAgents returns a plain 'output' string
        if isinstance(result.get("output"), str):
            output_text = result["output"]
        else:
            msgs = result.get("messages")
            if isinstance(msgs, list) and msgs:
                last = msgs[-1]

                # Case 2: LangChain chat message (AIMessage, etc.)
                if hasattr(last, "content"):
                    output_text = last.content
                # Case 3: plain dict with "content"
                elif isinstance(last, dict):
                    output_text = last.get("content")

    if not output_text:
        output_text = "No output generated."

    # write report
    workspace = Path("agent_workspace")
    workspace.mkdir(exist_ok=True)
    report_path = workspace / "report.md"
    report_path.write_text(f"# Report: {topic}\n\n{output_text}", encoding="utf-8")

    print(f"[AGENT] DONE â†’ {report_path}")

# def run_research(topic: str):
#     task = (
#         f"Deep research on {topic}. "
#         f"Plan steps, use tools as needed, and produce a final markdown report."
#     )

#     print("[AGENT] Invoking deep agent with task:")
#     print("        ", task)

#     # DeepAgents expects {"input": "..."} as top-level payload
#     # result = main_agent.invoke({"input": task})
#     result = main_agent.invoke(
#         {"messages": [{"role": "user", "content": task}]}, config={"single_run": True}
#     )

#     print("[AGENT] Deep agent finished, extracting output...")

#     # Try to pull a text answer out of result
#     output_text = None

#     if isinstance(result, dict):
#         if isinstance(result.get("output"), str):
#             output_text = result["output"]
#         elif isinstance(result.get("messages"), list) and result["messages"]:
#             last = result["messages"][-1]
#             if hasattr(last, "content"):
#                 output_text = last.content
#             elif isinstance(last, dict) and "content" in last:
#                 output_text = last["content"]

#     if not output_text:
#         output_text = "No output generated by the agent."

#     # ---- Write report to local folder ----
#     workspace = Path("agent_workspace")
#     workspace.mkdir(exist_ok=True)
#     report_path = workspace / "report.md"

#     with report_path.open("w", encoding="utf-8") as f:
#         f.write(f"# Research Report: {topic}\n\n{output_text}")

#     print(f"[AGENT] Research complete! Report written to {report_path}")
#     return result


if __name__ == "__main__":
    sanity_test()  # prove Claude works before we touch DeepAgents

    topic = input("Enter research topic: ")
    run_research(topic)
